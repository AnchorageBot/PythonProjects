[Markov chain or Markov process - Wikipedia](https://en.wikipedia.org/wiki/Markov_chain)

A Markov chain or Markov process is a stochastic model describing a sequence of possible events in which the probability
of each event depends only on the state attained in the previous event.Informally, this may be thought of as,
"What happens next depends only on the state of affairs now." A countably infinite sequence, in which the chain moves state
at discrete time steps, gives a discrete-time Markov chain (DTMC). A continuous-time process is called a continuous-time
Markov chain (CTMC). It is named after the Russian mathematician Andrey Markov.

- - - -

Books

* [Markov Models - Lazy Programmer](https://www.amazon.com/Markov-Models-Science-Unsupervised-Learning-ebook/dp/B01M1J1Y8C)

* [Understanding Markov Chains
Examples and Applications - Privault](https://link.springer.com/book/10.1007/978-981-13-0659-4)

Videos

* [Origin of Markov chains | Journey into information theory | Computer Science | Khan Academy](https://youtu.be/Ws63I3F7Moc?si=mjQqtHdwR_ROWWle)

* [An Intro to Markov chains with Python! - Adrian Dolinay](https://youtu.be/WT6jI8UgROI?si=WX-17SnJq3HvZt2q)

* [Markov Chains Clearly Explained! Part - 1 - Normalized Nerd](https://m.youtube.com/watch?v=i3AkTO9HLXo&t=455s)

* [Markov Chains: Simulation in Python | Stationary Distribution Computation | Part - 7 - Normalized Nerd](https://m.youtube.com/watch?v=G7FIQ9fXl6U)

- - - -

Documentation

[Matplotlib](https://matplotlib.org/stable/)

[Numpy](https://numpy.org/doc/stable/)

[Random](https://docs.python.org/3/library/random.html)
