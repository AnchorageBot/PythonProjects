[Hamilton–Jacobi–Bellman equation - Wiki](https://en.wikipedia.org/wiki/Hamilton–Jacobi–Bellman_equation)

The Hamilton-Jacobi-Bellman (HJB) equation is a nonlinear partial differential equation that provides necessary and sufficient conditions for optimality of a control
with respect to a loss function. Its solution is the value function of the optimal control problem which, once known, can be used to obtain the optimal control by taking
the maximizer (or minimizer) of the Hamiltonian involved in the HJB equation.
