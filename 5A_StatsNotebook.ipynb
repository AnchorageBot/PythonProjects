{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPUrk9gLGbVAtXF2GZIgVtT"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "This notebook takes a look at the results from a hypothetical slot machine through the lens of probability\n",
        "* Tutors:\n",
        "  * Anthropic's AI Claude\n",
        "  * Google's Gemini"
      ],
      "metadata": {
        "id": "sFLlh3vSbObX"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Given a slot machine and five observed payouts\n",
        "\n",
        "Observed numbers = [0,0,1.5,0,1.5]\n",
        "  * Sum = 3\n",
        "  * Average = 3/5 = 0.6\n",
        "  * Sample size = 5\n",
        "\n"
      ],
      "metadata": {
        "id": "a-ui6gt2FQ2B"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Methods used for developing probability estimates\n",
        "* Guess 1 = continous probability distribution, normal distribution\n",
        "* Guess 2 = discrete probability distribution, binomal distribution\n",
        "* Guess 3 = bayseian approach\n",
        "* Guess 4 = monte carlo approach"
      ],
      "metadata": {
        "id": "lvW3eQ7HFa_e"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "UXD-26UwbDLS",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "333d9788-c775-485f-ba88-65777e9d6d29"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Observed results: [0, 0, 1.5, 0, 1.5] \n",
            "\n",
            "Sample size: 5 \n",
            "\n",
            "Observed wins: 2 out of 5 spins\n",
            "\n",
            "Mean: 0.6\n",
            "\n",
            "Median: 0\n",
            "\n",
            "Standard deviation: 0.7348469228349535\n",
            "\n",
            "Binomial distribution 0.34559999999999974\n",
            "A discrete probability distribution/binomial might be more appropriate than a continuous/normal one.\n",
            "This is because it's similar to a 'success/failure' pattern.\n",
            "This value represents the relative likelihood of observing a payout around 0.6 units if the payouts truly follow a binomial distribution.\n",
            "\n",
            "Normal distribution: 0.38899888689271633\n",
            "When we calculate the normal distribution probability density at the mean (x = 0.6), we get approximately 0.4843. \n",
            "This value represents the relative likelihood of observing a payout around 0.6 units if the payouts truly follow a normal distribution.\n",
            "\n",
            "Bayesian posterior probability of winning: 0.4286\n"
          ]
        }
      ],
      "source": [
        "#Given a slot machine and five observed payouts\n",
        "\n",
        "#Observed numbers = [0,0,1.5,0,1.5]\n",
        "    #Sum = 3\n",
        "    #Average = 3/5 = 0.6\n",
        "    #Sample size = 5\n",
        "\n",
        "    #Guess 1 = continous probability distribution, normal distribution\n",
        "    #Guess 2 = discrete probability distribution, binomal distribution\n",
        "    #Guess 3 = bayseian approach to a probability estimate\n",
        "    #Guess 4 = monte carlo approach to a probability estimate\n",
        "\n",
        "import numpy as np\n",
        "from scipy.stats import binom\n",
        "\n",
        "def calc_mean(numbers):\n",
        "    '''\n",
        "    Manual mean calculator\n",
        "    '''\n",
        "\n",
        "    total = sum(numbers)\n",
        "    pop = len(numbers)\n",
        "\n",
        "    mean = total/pop\n",
        "\n",
        "    return mean\n",
        "\n",
        "def calc_median(numbers):\n",
        "    \"\"\"\n",
        "    Manual median calculator\n",
        "\n",
        "    Tutor: Anthropic's AI Claude\n",
        "    \"\"\"\n",
        "\n",
        "    sorted_numbers = sorted(numbers)\n",
        "    n = len(sorted_numbers)\n",
        "\n",
        "    if n % 2 == 0:\n",
        "        # If even length, average the two middle numbers\n",
        "        return (sorted_numbers[n//2 - 1] + sorted_numbers[n//2]) / 2\n",
        "    else:\n",
        "        # If odd length, return the middle number\n",
        "        return sorted_numbers[n//2]\n",
        "\n",
        "def calc_standard_deviation(numbers):\n",
        "    \"\"\"\n",
        "    Manual Standard Deviation Calculator\n",
        "\n",
        "    Calculates the spread of the slot machine payouts\n",
        "\n",
        "    Tutor: Anthropic's AI Claude\n",
        "    \"\"\"\n",
        "    n = len(numbers)\n",
        "\n",
        "    # Calculate mean\n",
        "    mean = sum(numbers) / n\n",
        "\n",
        "    # Calculate squared differences from mean\n",
        "    squared_diff_sum = sum((x - mean) ** 2 for x in numbers)\n",
        "\n",
        "    # Calculate variance and standard deviation\n",
        "    variance = squared_diff_sum / n\n",
        "    std_dev = variance ** 0.5\n",
        "\n",
        "    return std_dev\n",
        "\n",
        "#import numpy as np\n",
        "\n",
        "def normal_distribution(x, mu, sigma):\n",
        "    \"\"\"\n",
        "    Calculates the normal distribution probability density at point x\n",
        "\n",
        "    The equation gives the probability density at any point x for a distribution with specified mean and standard deviation.\n",
        "\n",
        "    When we calculate the normal distribution probability density at the mean (x = 0.6), we get approximately 0.4843. This value represents\n",
        "    the relative likelihood of observing a payout around 0.6 units if the payouts truly follow a normal distribution.\n",
        "\n",
        "    Uses the numpy library\n",
        "\n",
        "    Parameters:\n",
        "    x (float): Point at which to evaluate the distribution\n",
        "    mu (float): Mean of the distribution\n",
        "    sigma (float): Standard deviation of the distribution\n",
        "\n",
        "    Returns:\n",
        "    float: Probability density at point x\n",
        "\n",
        "    Tutor: Anthropic's AI Claude\n",
        "\n",
        "    \"\"\"\n",
        "    nd = (1 / (sigma * np.sqrt(2 * np.pi))) * np.exp(-0.5 * ((x - mu) / sigma)**2)\n",
        "\n",
        "    return nd\n",
        "\n",
        "#import numpy as np\n",
        "#from scipy.stats import binom\n",
        "\n",
        "def binomial_distribution(k, n, p):\n",
        "    \"\"\"\n",
        "    Calculates the binomial probability mass function at point k\n",
        "    The equation gives the probability of exactly k successes in n trials,\n",
        "    where each trial has probability p of success.\n",
        "\n",
        "    For the slot machine example with [0, 0, 1.5, 0, 1.5]:\n",
        "    - n = 5 (total spins)\n",
        "    - k = 2 (number of 1.5 payouts)\n",
        "    - p = 0.4 (probability of getting 1.5, which occurred 2/5 times)\n",
        "    Using these values would give us the probability of getting exactly 2 payouts of 1.5 in 5 spins.\n",
        "    Uses the scipy.stats library for accurate calculation\n",
        "\n",
        "    Parameters:\n",
        "    k (int): Number of successes to calculate probability for\n",
        "    n (int): Total number of trials\n",
        "    p (float): Probability of success on each trial (between 0 and 1)\n",
        "\n",
        "    Returns:\n",
        "    float: Probability mass for exactly k successes\n",
        "\n",
        "    Uses the numpy and scipy.stats libraries for accurate calculation\n",
        "\n",
        "    Tutor: Anthropic's AI Claude\n",
        "\n",
        "    Examples:\n",
        "    >>> binomial_distribution(k=2, n=5, p=0.4)  # Probability of 2 successes in 5 trials with 0.4 probability each\n",
        "    0.2304\n",
        "    \"\"\"\n",
        "    # Using scipy's binom.pmf for accurate calculation\n",
        "    # Alternative manual calculation would be:\n",
        "    # probability = (np.math.comb(n, k)) * (p**k) * ((1-p)**(n-k))\n",
        "    probability = binom.pmf(k, n, p)\n",
        "    return probability\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "def bayesian_slot_probability(observed_data, prior_prob=0.4):\n",
        "    \"\"\"\n",
        "    Bayesian approach to calculating the probability of winning on a slot machine\n",
        "    based on observed data.\n",
        "\n",
        "    Parameters:\n",
        "    observed_data (list): List of observed payouts (e.g., [0, 0, 1.5, 0, 1.5])\n",
        "    prior_prob (float): Prior probability of winning, defaults to 0.4 based on observed frequency\n",
        "\n",
        "    Returns:\n",
        "    float: Posterior probability of winning on the next spin\n",
        "\n",
        "    The function uses Bayes' theorem:\n",
        "    P(Win|Data) = P(Data|Win) * P(Win) / P(Data)\n",
        "\n",
        "    For slot machines:\n",
        "    - P(Win|Data) is our updated probability of winning after seeing the data\n",
        "    - P(Data|Win) is probability of seeing our specific sequence given win probability\n",
        "    - P(Win) is our prior belief about win probability (0.4 default)\n",
        "    - P(Data) is probability of observing our sequence under any probability\n",
        "\n",
        "\n",
        "\n",
        "    # Count wins (payouts > 0) and total observations\n",
        "    wins = sum(1 for payout in observed_data if payout > 0)\n",
        "    total_spins = len(observed_data)\n",
        "\n",
        "    # Calculate likelihood: P(Data|Win)\n",
        "    # This is the probability of observing this many wins given our prior\n",
        "    likelihood = (prior_prob ** wins) * ((1 - prior_prob) ** (total_spins - wins))\n",
        "\n",
        "    # Calculate marginal probability: P(Data)\n",
        "    # For simplification, we can use the observed frequency\n",
        "    marginal = wins / total_spins\n",
        "\n",
        "    # Calculate posterior probability using Bayes' theorem\n",
        "    posterior_prob = (likelihood * prior_prob) / marginal if marginal > 0 else prior_prob\n",
        "\n",
        "    # Ensure probability is between 0 and 1\n",
        "    posterior_prob = min(1.0, max(0.0, posterior_prob))\n",
        "\n",
        "\n",
        "    P(A|B) = (P(B|A) * P(A)) / P(B)\n",
        "\n",
        "    P(A|B) = Posterior probability\n",
        "    P(B|A) = Likelihood\n",
        "    P(A) = Prior probability\n",
        "    P(B) = Marginal probability\n",
        "\n",
        "    Tutors:\n",
        "      Google's AI Gemini\n",
        "      Anthropic's AI Claude\n",
        "\n",
        "    \"\"\"\n",
        "    # Count wins (payouts > 0) and total observations\n",
        "    wins = sum(1 for payout in observed_data if payout > 0)\n",
        "    total_spins = len(observed_data)\n",
        "\n",
        "    # Use the Beta distribution conjugate prior\n",
        "    # Beta(α + wins, β + losses) where α=β=1 for uniform prior\n",
        "    alpha = 1 + wins\n",
        "    beta = 1 + (total_spins - wins)\n",
        "\n",
        "    # Posterior probability is the expected value of the Beta distribution\n",
        "    posterior_prob = alpha / (alpha + beta)\n",
        "\n",
        "    return posterior_prob\n",
        "\n",
        "\n",
        "def monte_carlo():\n",
        "    \"\"\"\n",
        "    Monte Carlo approach to calculating probability\n",
        "\n",
        "    E(x) = Σ(x_i * p_i) / Σ(p_i)\n",
        "\n",
        "    E(x) = Expected value\n",
        "    x_i = Individual values\n",
        "    p_i = Probabilities for each value\n",
        "\n",
        "    Tutors:\n",
        "      Google's AI Gemini\n",
        "      Anthropic's AI Claude\n",
        "\n",
        "    \"\"\"\n",
        "    E = 0\n",
        "    for i in range(len(numbers)):\n",
        "        E += numbers[i] * p[i]\n",
        "\n",
        "    return E\n",
        "\n",
        "\n",
        "def estimate_average_slot_payout(n_runs):\n",
        "    \"\"\"Run the slot machine n_runs times and return the average net profit per run.\n",
        "\n",
        "    Example calls (note that return value is nondeterministic!):\n",
        "\n",
        "    Tutors:\n",
        "      Google's Gemini\n",
        "      Anthropic's AI Claude\n",
        "\n",
        "    \"\"\"\n",
        "    numbers = [0,0,1.5,0,1.5]\n",
        "\n",
        "    sum = 0\n",
        "    for i in range(n_runs):\n",
        "        sum += sum(numbers)\n",
        "\n",
        "    total_profit = 0\n",
        "    for i in range(n_runs):\n",
        "        total_profit += sum(numbers)\n",
        "\n",
        "    pop = len(numbers)\n",
        "\n",
        "    total_profit = sum(numbers)/pop\n",
        "    average_profit = total_profit / n_runs\n",
        "\n",
        "    return average_profit\n",
        "\n",
        "# Observed results\n",
        "numbers = [0,0,1.5,0,1.5]\n",
        "print(\"Observed results:\", numbers, \"\\n\")\n",
        "print(\"Sample size:\", len(numbers), \"\\n\")\n",
        "print(f\"Observed wins: {sum(1 for x in numbers if x > 0)} out of {len(numbers)} spins\\n\")\n",
        "\n",
        "#print(\"Mean is \", calc_mean(numbers))\n",
        "mean = calc_mean(numbers)\n",
        "print(f\"Mean: {mean}\\n\")\n",
        "\n",
        "#print(\"Median is \", calc_median(numbers))\n",
        "median = calc_median(numbers)\n",
        "print(f\"Median: {median}\\n\")\n",
        "\n",
        "#print(\"Standard deviation is \", calc_standard_deviation(numbers))\n",
        "StanDev = calc_standard_deviation(numbers)\n",
        "print(f\"Standard deviation: {StanDev}\\n\")\n",
        "\n",
        "# Example - binomial approach\n",
        "k = 2 #number of 1.5 payouts\n",
        "n = 5 #total spins\n",
        "p= 0.4 #probability of getting 1.5, which occurred 2/5 times\n",
        "print(\"Binomial distribution\", binomial_distribution(k, n, p))\n",
        "print(\"A discrete probability distribution/binomial might be more appropriate than a continuous/normal one.\")\n",
        "print(\"This is because it's similar to a 'success/failure' pattern.\")\n",
        "print(\"This value represents the relative likelihood of observing a payout around 0.6 units if the payouts truly follow a binomial distribution.\\n\")\n",
        "\n",
        "# Example - normal/gaussian approach\n",
        "x = mean # When we evaluate the normal distribution at x = mean (0.6), we get the peak density for your distribution.\n",
        "mu = median\n",
        "sigma = StanDev\n",
        "print(\"Normal distribution:\", normal_distribution(x, mu, sigma))\n",
        "print(\"When we calculate the normal distribution probability density at the mean (x = 0.6), we get approximately 0.4843. \")\n",
        "print(\"This value represents the relative likelihood of observing a payout around 0.6 units if the payouts truly follow a normal distribution.\\n\")\n",
        "\n",
        "# Example - bayesian approach\n",
        "posterior_probability = bayesian_slot_probability(numbers)\n",
        "print(f\"Bayesian posterior probability of winning: {posterior_probability:.4f}\")"
      ]
    }
  ]
}