{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMQO7xNqMet5yWtJ4rm8eAv"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "Coursera's Generative AI for Data Science with Copilot\n",
        "\n",
        "* Handwritten Digit Image Notebook - MNIST Dataset"
      ],
      "metadata": {
        "id": "ZKzx5Hu8Yp6c"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Tutor: Google Gemini 2.0, Advanced Experimental"
      ],
      "metadata": {
        "id": "PDzQKnkhZDnJ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Key improvements and explanations in this complete, runnable code:\n",
        "\n",
        "Complete Training Loop: Includes data loading (MNIST), training, and testing loops. The train() and test() functions are fully implemented.\n",
        "\n",
        "* MNIST Data Loading: Correctly uses torchvision.datasets.MNIST and DataLoader to handle the MNIST dataset. The transform is set up to convert images to tensors in the range [0, 1].\n",
        "\n",
        "* Device Handling: Uses torch.device to automatically use a GPU if available, otherwise falls back to CPU. The model and data are moved to the correct device.\n",
        "\n",
        "* Loss Function: The loss_function calculates both the reconstruction loss (Binary Cross-Entropy) and the KL divergence. Crucially, reduction='sum' is used in the BCE loss, which is the standard approach for VAEs (summing over all pixels and all samples in the batch).\n",
        "\n",
        "* Input/Output Shapes: The code now explicitly handles the expected input shape of MNIST images (1x28x28). The convolutional layers are set up to process this correctly. The Unflatten layer in the decoder correctly reshapes the latent vector back into a 3D tensor for the transposed convolutions.\n",
        "\n",
        "* Sigmoid Activation: The decoder's final layer uses a Sigmoid activation function, which is essential to constrain the output pixel values to the range [0, 1], matching the normalized MNIST data.\n",
        "\n",
        "* Optimizer: Uses the Adam optimizer, which is a good general-purpose optimizer for deep learning.\n",
        "\n",
        "* Reparameterization Trick: The reparameterize function is correctly implemented, ensuring proper gradient flow during training.\n",
        "\n",
        "* Latent Dimension: The latent_dim is a parameter to the VAE class, allowing you to experiment with different sizes of the latent space.\n",
        "\n",
        "* Generation of Samples: Added a section within the test() function to generate new samples from the trained VAE by sampling from the standard normal distribution in the latent space.\n",
        "\n",
        "* Print Statements: Adds print statements to show training progress, including the average loss per epoch.\n",
        "\n",
        "* Batching: Processes data in batches, which is critical for efficient training on GPUs.\n",
        "\n",
        "* No Labels Needed (Unsupervised): Correctly ignores the labels from the MNIST dataset in the training loop, as VAEs are unsupervised learning models."
      ],
      "metadata": {
        "id": "phLAiYRgZLua"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "An-dwylwYjL4",
        "outputId": "90f8d1cc-f5aa-4c7b-e336-d5c2528e36e8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 1, Batch: 0, Loss: 648.296142578125\n",
            "Epoch: 1, Batch: 100, Loss: 207.4195556640625\n",
            "Epoch: 1, Batch: 200, Loss: 194.0279083251953\n",
            "Epoch: 1, Batch: 300, Loss: 176.4379119873047\n",
            "Epoch: 1, Batch: 400, Loss: 154.67413330078125\n",
            "====> Epoch: 1 Average loss: 197.44828819986978\n",
            "Epoch: 2, Batch: 0, Loss: 149.11216735839844\n",
            "Epoch: 2, Batch: 100, Loss: 136.32981872558594\n",
            "Epoch: 2, Batch: 200, Loss: 129.10147094726562\n",
            "Epoch: 2, Batch: 300, Loss: 126.16657257080078\n",
            "Epoch: 2, Batch: 400, Loss: 119.9908218383789\n",
            "====> Epoch: 2 Average loss: 128.29019767252603\n",
            "Epoch: 3, Batch: 0, Loss: 123.14994049072266\n",
            "Epoch: 3, Batch: 100, Loss: 114.07067108154297\n",
            "Epoch: 3, Batch: 200, Loss: 114.66558837890625\n",
            "Epoch: 3, Batch: 300, Loss: 112.60355377197266\n",
            "Epoch: 3, Batch: 400, Loss: 112.46279907226562\n",
            "====> Epoch: 3 Average loss: 114.31106189778646\n",
            "Epoch: 4, Batch: 0, Loss: 112.81857299804688\n",
            "Epoch: 4, Batch: 100, Loss: 110.68171691894531\n",
            "Epoch: 4, Batch: 200, Loss: 103.15380859375\n",
            "Epoch: 4, Batch: 300, Loss: 106.52081298828125\n",
            "Epoch: 4, Batch: 400, Loss: 107.79624938964844\n",
            "====> Epoch: 4 Average loss: 109.11925966796875\n",
            "Epoch: 5, Batch: 0, Loss: 105.7816162109375\n",
            "Epoch: 5, Batch: 100, Loss: 107.40278625488281\n",
            "Epoch: 5, Batch: 200, Loss: 107.15435791015625\n",
            "Epoch: 5, Batch: 300, Loss: 104.14884185791016\n",
            "Epoch: 5, Batch: 400, Loss: 108.72731018066406\n",
            "====> Epoch: 5 Average loss: 106.5410263671875\n",
            "Epoch: 6, Batch: 0, Loss: 101.38121032714844\n",
            "Epoch: 6, Batch: 100, Loss: 103.84862518310547\n",
            "Epoch: 6, Batch: 200, Loss: 101.3119125366211\n",
            "Epoch: 6, Batch: 300, Loss: 107.03173828125\n",
            "Epoch: 6, Batch: 400, Loss: 103.08509826660156\n",
            "====> Epoch: 6 Average loss: 104.96362874348958\n",
            "Epoch: 7, Batch: 0, Loss: 102.95097351074219\n",
            "Epoch: 7, Batch: 100, Loss: 105.21226501464844\n",
            "Epoch: 7, Batch: 200, Loss: 99.790771484375\n",
            "Epoch: 7, Batch: 300, Loss: 105.01896667480469\n",
            "Epoch: 7, Batch: 400, Loss: 98.90302276611328\n",
            "====> Epoch: 7 Average loss: 103.86820528971354\n",
            "Epoch: 8, Batch: 0, Loss: 100.93321990966797\n",
            "Epoch: 8, Batch: 100, Loss: 102.0709457397461\n",
            "Epoch: 8, Batch: 200, Loss: 102.10664367675781\n",
            "Epoch: 8, Batch: 300, Loss: 107.54464721679688\n",
            "Epoch: 8, Batch: 400, Loss: 101.31449127197266\n",
            "====> Epoch: 8 Average loss: 103.03428321940105\n",
            "Epoch: 9, Batch: 0, Loss: 101.51654815673828\n",
            "Epoch: 9, Batch: 100, Loss: 101.53567504882812\n",
            "Epoch: 9, Batch: 200, Loss: 102.58565521240234\n",
            "Epoch: 9, Batch: 300, Loss: 103.0803451538086\n",
            "Epoch: 9, Batch: 400, Loss: 100.34269714355469\n",
            "====> Epoch: 9 Average loss: 102.37874184570312\n",
            "Epoch: 10, Batch: 0, Loss: 101.23849487304688\n",
            "Epoch: 10, Batch: 100, Loss: 101.17327880859375\n",
            "Epoch: 10, Batch: 200, Loss: 103.08291625976562\n",
            "Epoch: 10, Batch: 300, Loss: 97.78361511230469\n",
            "Epoch: 10, Batch: 400, Loss: 102.61129760742188\n",
            "====> Epoch: 10 Average loss: 101.93519817708334\n",
            "====> Test set loss: 101.35240432128906\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torchvision import datasets, transforms\n",
        "from torch.utils.data import DataLoader\n",
        "\n",
        "class VAE(nn.Module):\n",
        "    def __init__(self, latent_dim=20):  # Added a default latent_dim\n",
        "        super(VAE, self).__init__()\n",
        "        self.latent_dim = latent_dim\n",
        "\n",
        "        # Encoder\n",
        "        self.encoder = nn.Sequential(\n",
        "            nn.Conv2d(1, 32, kernel_size=3, stride=2, padding=1),  # Input: 1x28x28 (MNIST)\n",
        "            nn.ReLU(),\n",
        "            nn.Conv2d(32, 64, kernel_size=3, stride=2, padding=1),\n",
        "            nn.ReLU(),\n",
        "            nn.Flatten(),\n",
        "            nn.Linear(64 * 7 * 7, 128), #  7x7 because of two stride=2 convolutions.  28 / 2 / 2 = 7\n",
        "            nn.ReLU()\n",
        "        )\n",
        "\n",
        "        # Latent Space\n",
        "        self.z_mean = nn.Linear(128, latent_dim)\n",
        "        self.z_log_var = nn.Linear(128, latent_dim)\n",
        "\n",
        "        # Decoder\n",
        "        self.decoder = nn.Sequential(\n",
        "            nn.Linear(latent_dim, 128),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(128, 64 * 7 * 7),\n",
        "            nn.ReLU(),\n",
        "            nn.Unflatten(1, (64, 7, 7)),  # Reshape to (64, 7, 7)\n",
        "            nn.ConvTranspose2d(64, 32, kernel_size=3, stride=2, padding=1, output_padding=1),\n",
        "            nn.ReLU(),\n",
        "            nn.ConvTranspose2d(32, 1, kernel_size=3, stride=2, padding=1, output_padding=1),\n",
        "            nn.Sigmoid()  # Sigmoid to get output between 0 and 1 (pixel values)\n",
        "        )\n",
        "\n",
        "    def encode(self, x):\n",
        "        x = self.encoder(x)\n",
        "        mu = self.z_mean(x)\n",
        "        log_var = self.z_log_var(x)\n",
        "        return mu, log_var\n",
        "\n",
        "    def reparameterize(self, mu, log_var):\n",
        "        std = torch.exp(0.5 * log_var)\n",
        "        eps = torch.randn_like(std)\n",
        "        return mu + eps * std\n",
        "\n",
        "    def decode(self, z):\n",
        "        x_hat = self.decoder(z)\n",
        "        return x_hat\n",
        "\n",
        "    def forward(self, x):\n",
        "        mu, log_var = self.encode(x)\n",
        "        z = self.reparameterize(mu, log_var)\n",
        "        x_hat = self.decode(z)\n",
        "        return x_hat, mu, log_var\n",
        "\n",
        "\n",
        "# --- Loss Function ---\n",
        "def loss_function(x_hat, x, mu, log_var):\n",
        "    BCE = F.binary_cross_entropy(x_hat, x, reduction='sum')  # Reconstruction loss\n",
        "    KLD = -0.5 * torch.sum(1 + log_var - mu.pow(2) - log_var.exp()) # KL Divergence\n",
        "    return BCE + KLD\n",
        "\n",
        "\n",
        "# --- Data Loading (MNIST) ---\n",
        "transform = transforms.Compose([\n",
        "    transforms.ToTensor(),  # Converts to tensor and scales to [0, 1]\n",
        "    # No Normalization needed;  Sigmoid in decoder handles 0-1 range.\n",
        "])\n",
        "\n",
        "train_dataset = datasets.MNIST(root='./data', train=True, download=True, transform=transform)\n",
        "test_dataset = datasets.MNIST(root='./data', train=False, download=True, transform=transform)\n",
        "\n",
        "train_loader = DataLoader(train_dataset, batch_size=128, shuffle=True)\n",
        "test_loader = DataLoader(test_dataset, batch_size=128, shuffle=False)\n",
        "\n",
        "\n",
        "# --- Training Loop ---\n",
        "def train(model, optimizer, epochs=10):\n",
        "    model.train()\n",
        "    for epoch in range(epochs):\n",
        "        train_loss = 0\n",
        "        for batch_idx, (data, _) in enumerate(train_loader): # MNIST has no labels for this task\n",
        "            data = data.to(device)  # Move data to device\n",
        "            optimizer.zero_grad()\n",
        "            x_hat, mu, log_var = model(data)\n",
        "            loss = loss_function(x_hat, data, mu, log_var)\n",
        "            loss.backward()\n",
        "            train_loss += loss.item()\n",
        "            optimizer.step()\n",
        "\n",
        "            if batch_idx % 100 == 0:\n",
        "                print(f'Epoch: {epoch+1}, Batch: {batch_idx}, Loss: {loss.item() / len(data)}') #Average loss per sample\n",
        "\n",
        "        print(f'====> Epoch: {epoch+1} Average loss: {train_loss / len(train_loader.dataset)}')\n",
        "\n",
        "\n",
        "# --- Testing ---\n",
        "def test(model):\n",
        "    model.eval()\n",
        "    test_loss = 0\n",
        "    with torch.no_grad():\n",
        "        for data, _ in test_loader:\n",
        "            data = data.to(device)\n",
        "            x_hat, mu, log_var = model(data)\n",
        "            test_loss += loss_function(x_hat, data, mu, log_var).item()\n",
        "\n",
        "    test_loss /= len(test_loader.dataset)\n",
        "    print(f'====> Test set loss: {test_loss}')\n",
        "\n",
        "    # --- Generate Samples ---\n",
        "    with torch.no_grad():\n",
        "        z = torch.randn(64, model.latent_dim).to(device) # Sample from standard normal\n",
        "        generated_images = model.decode(z).cpu()\n",
        "        # Save or display generated_images (e.g., using torchvision.utils.save_image)\n",
        "\n",
        "\n",
        "# --- Device Setup ---\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "# --- Model Initialization ---\n",
        "model = VAE().to(device)\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=1e-3)\n",
        "\n",
        "# --- Run Training and Testing ---\n",
        "train(model, optimizer, epochs=10)  # Train for more epochs (e.g., 20)\n",
        "test(model)"
      ]
    }
  ]
}